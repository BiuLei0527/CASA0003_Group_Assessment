{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ng/k_cplh696b5gn6zhx9znmp100000gn/T/ipykernel_31838/347346336.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  q1 = pd.read_csv('/Users/xilver/Desktop/CASA0003/Group Assessment/Data/indego-trips-2024-q1.csv')\n",
      "/var/folders/ng/k_cplh696b5gn6zhx9znmp100000gn/T/ipykernel_31838/347346336.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  q2 = pd.read_csv('/Users/xilver/Desktop/CASA0003/Group Assessment/Data/indego-trips-2024-q2.csv')\n",
      "/var/folders/ng/k_cplh696b5gn6zhx9znmp100000gn/T/ipykernel_31838/347346336.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  q3 = pd.read_csv('/Users/xilver/Desktop/CASA0003/Group Assessment/Data/indego-trips-2024-q3.csv')\n",
      "/var/folders/ng/k_cplh696b5gn6zhx9znmp100000gn/T/ipykernel_31838/347346336.py:4: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  q4 = pd.read_csv('/Users/xilver/Desktop/CASA0003/Group Assessment/Data/indego-trips-2024-q4.csv')\n"
     ]
    }
   ],
   "source": [
    "q1 = pd.read_csv('/Users/xilver/Desktop/CASA0003/Group Assessment/Data/indego-trips-2024-q1.csv')\n",
    "q2 = pd.read_csv('/Users/xilver/Desktop/CASA0003/Group Assessment/Data/indego-trips-2024-q2.csv')\n",
    "q3 = pd.read_csv('/Users/xilver/Desktop/CASA0003/Group Assessment/Data/indego-trips-2024-q3.csv')\n",
    "q4 = pd.read_csv('/Users/xilver/Desktop/CASA0003/Group Assessment/Data/indego-trips-2024-q4.csv')\n",
    "census_tract = gpd.read_file('/Users/xilver/Desktop/CASA0003/Group Assessment/24137945_CASA0003_individual_visualisation/geojson/Census_Tracts_2010.geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = pd.read_csv('/Users/xilver/Desktop/CASA0003/Group Assessment/Data/indego-stations-2025-04-01.csv')\n",
    "stations_start = station.rename(columns={\n",
    "    'Station_ID': 'start_station',\n",
    "    'Station_Name': 'start_station_name'\n",
    "})\n",
    "stations_end = station.rename(columns={\n",
    "    'Station_ID': 'end_station',\n",
    "    'Station_Name': 'end_station_name'\n",
    "})\n",
    "\n",
    "q1 = q1.merge(stations_start, on='start_station', how='left')\n",
    "q1 = q1.merge(stations_end, on='end_station', how='left')\n",
    "\n",
    "q2 = q2.merge(stations_start, on='start_station', how='left')\n",
    "q2 = q2.merge(stations_end, on='end_station', how='left')\n",
    "\n",
    "q3 = q3.merge(stations_start, on='start_station', how='left')\n",
    "q3 = q3.merge(stations_end, on='end_station', how='left')\n",
    "\n",
    "q4 = q4.merge(stations_start, on='start_station', how='left')\n",
    "q4 = q4.merge(stations_end, on='end_station', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = [\n",
    "    \"trip_id\", \"duration\", \"start_time\", \"end_time\",\n",
    "    \"start_station_name\", \"start_lat\", \"start_lon\",\n",
    "    \"end_station_name\", \"end_lat\", \"end_lon\",\n",
    "    \"bike_id\", \"plan_duration\", \"trip_route_category\",\n",
    "    \"passholder_type\", \"bike_type\"\n",
    "]\n",
    "q1 = q1[keep_columns]\n",
    "q2 = q2[keep_columns]\n",
    "q3 = q3[keep_columns]\n",
    "q4 = q4[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1['start_time'] = pd.to_datetime(q1['start_time'])\n",
    "q1['end_time'] = pd.to_datetime(q1['end_time'])\n",
    "\n",
    "q2['start_time'] = pd.to_datetime(q2['start_time'])\n",
    "q2['end_time'] = pd.to_datetime(q2['end_time'])\n",
    "\n",
    "q3['start_time'] = pd.to_datetime(q3['start_time'])\n",
    "q3['end_time'] = pd.to_datetime(q3['end_time'])\n",
    "\n",
    "q4['start_time'] = pd.to_datetime(q4['start_time'])\n",
    "q4['end_time'] = pd.to_datetime(q4['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = q1.dropna(subset=['start_station_name', 'end_station_name', 'start_lat', 'start_lon', 'end_lat', 'end_lon'])\n",
    "q2 = q2.dropna(subset=['start_station_name', 'end_station_name', 'start_lat', 'start_lon', 'end_lat', 'end_lon'])\n",
    "q3 = q3.dropna(subset=['start_station_name', 'end_station_name', 'start_lat', 'start_lon', 'end_lat', 'end_lon'])\n",
    "q4 = q4.dropna(subset=['start_station_name', 'end_station_name', 'start_lat', 'start_lon', 'end_lat', 'end_lon'])\n",
    "\n",
    "q1['od_pair'] = q1['start_station_name'].astype(str) + '-' + q1['end_station_name'].astype(str)\n",
    "q2['od_pair'] = q2['start_station_name'].astype(str) + '-' + q2['end_station_name'].astype(str)\n",
    "q3['od_pair'] = q3['start_station_name'].astype(str) + '-' + q3['end_station_name'].astype(str)\n",
    "q4['od_pair'] = q4['start_station_name'].astype(str) + '-' + q4['end_station_name'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([q1, q2, q3, q4], ignore_index=True)\n",
    "all_data = all_data[all_data['trip_route_category'] != 'Round Trip']\n",
    "all_data = all_data[all_data['start_station_name'] != all_data['end_station_name']]\n",
    "all_data['month'] = all_data['start_time'].dt.month\n",
    "\n",
    "for month in range(1, 13):\n",
    "    df_month = all_data[all_data['month'] == month]\n",
    "    \n",
    "    od_matrix = df_month.groupby('od_pair').agg(\n",
    "    start_station_name=('start_station_name', 'first'),\n",
    "    end_station_name=('end_station_name', 'first'),\n",
    "    start_lat=('start_lat', 'first'),\n",
    "    start_lon=('start_lon', 'first'),\n",
    "    end_lat=('end_lat', 'first'),\n",
    "    end_lon=('end_lon', 'first'),\n",
    "    month=('month', 'first'))\n",
    "\n",
    "    od_matrix['trip_count'] = df_month.groupby('od_pair').size().values\n",
    "    od_matrix['geometry'] = od_matrix.apply(lambda row: LineString([(row['start_lon'], row['start_lat']), (row['end_lon'], row['end_lat'])]), axis=1)\n",
    "    od_gdf = gpd.GeoDataFrame(od_matrix, geometry='geometry', crs='EPSG:4326')\n",
    "    output_path = f'/Users/xilver/Desktop/CASA0003/Group Assessment/Monthly Flow/od_flows_month_{month}.geojson'\n",
    "    od_gdf.to_file(output_path, driver='GeoJSON')\n",
    "\n",
    "od_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Trips：\n",
      "Month 1: 46577 records\n",
      "Month 2: 59688 records\n",
      "Month 3: 73944 records\n",
      "Month 4: 94302 records\n",
      "Month 5: 115933 records\n",
      "Month 6: 127584 records\n",
      "Month 7: 125188 records\n",
      "Month 8: 122868 records\n",
      "Month 9: 127341 records\n",
      "Month 10: 128789 records\n",
      "Month 11: 92801 records\n",
      "Month 12: 56056 records\n"
     ]
    }
   ],
   "source": [
    "print(\"Monthly Trips：\")\n",
    "for month in range(1, 13):\n",
    "    df_month = all_data[all_data['month'] == month]\n",
    "    print(f\"Month {month}: {len(df_month)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['start_date'] = all_data['start_time'].dt.date\n",
    "all_data['end_date'] = all_data['end_time'].dt.date\n",
    "borrow_daily = all_data.groupby(['start_station_name', 'month', 'start_date']).size().reset_index(name='borrow_count')\n",
    "\n",
    "return_daily = all_data.groupby(['end_station_name', 'month', 'end_date']).size().reset_index(name='return_count')\n",
    "\n",
    "stations = all_data[['start_station_name', 'start_lat', 'start_lon']].drop_duplicates().rename(columns={'start_station_name': 'station_name', 'start_lat': 'lat', 'start_lon': 'lon'})\n",
    "borrow_daily = borrow_daily.merge(stations, left_on='start_station_name', right_on='station_name', how='left')\n",
    "return_daily = return_daily.merge(stations, left_on='end_station_name', right_on='station_name', how='left')\n",
    "\n",
    "daily_activity = pd.merge(borrow_daily, return_daily, \n",
    "                         left_on=['station_name', 'month', 'start_date'], \n",
    "                         right_on=['station_name', 'month', 'end_date'], \n",
    "                         how='outer', \n",
    "                         suffixes=('_borrow', '_return')).fillna(0)\n",
    "\n",
    "\n",
    "daily_activity['net_activity'] = daily_activity['borrow_count'] - daily_activity['return_count']\n",
    "daily_activity = daily_activity.rename(columns={'start_date': 'date'}).drop(columns=['end_date'])\n",
    "\n",
    "def fill_dates(df, stations):\n",
    "    stations_list = stations['station_name'].unique()\n",
    "   \n",
    "    dates = []\n",
    "    for month in range(1, 13):\n",
    "        month_dates = pd.date_range(start=f'2024-{month:02d}-01', end=f'2024-{month:02d}-{pd.Period(f'2024-{month:02d}').days_in_month}', freq='D').date\n",
    "        for date in month_dates:\n",
    "            for station in stations_list:\n",
    "                dates.append({'station_name': station, 'month': month, 'date': date})\n",
    "    full_df = pd.DataFrame(dates)\n",
    "\n",
    "    daily_activity_filled = pd.merge(full_df, df, on=['station_name', 'month', 'date'], how='left').fillna(0)\n",
    "\n",
    "    daily_activity_filled = daily_activity_filled.merge(stations, on='station_name', how='left')\n",
    "    daily_activity_filled['net_activity'] = daily_activity_filled['borrow_count'] - daily_activity_filled['return_count']\n",
    "    \n",
    "    return daily_activity_filled\n",
    "\n",
    "daily_activity = fill_dates(daily_activity, stations)\n",
    "columns_to_keep = ['station_name', 'month', 'date', 'borrow_count', 'return_count', 'net_activity', 'lat', 'lon']\n",
    "daily_activity = daily_activity[columns_to_keep]\n",
    "daily_activity_sorted = daily_activity.sort_values(by=['station_name', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_gdf = gpd.GeoDataFrame(daily_activity_sorted, \n",
    "                             geometry=gpd.points_from_xy(daily_activity_sorted['lon'], daily_activity_sorted['lat']), \n",
    "                             crs='EPSG:4326')\n",
    "\n",
    "for month in range(1, 13):\n",
    "    month_gdf = daily_gdf[daily_gdf['month'] == month]\n",
    "    if not month_gdf.empty:\n",
    "        output_path = f'/Users/xilver/Desktop/CASA0003/Group Assessment/Net Count/station_daily_activity_month_{month}.geojson'\n",
    "        month_gdf.to_file(output_path, driver='GeoJSON')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 106202 entries, 0 to 106201\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   station_name        106202 non-null  object \n",
      " 1   month               106202 non-null  int64  \n",
      " 2   date                106202 non-null  object \n",
      " 3   start_station_name  106202 non-null  object \n",
      " 4   borrow_count        106202 non-null  float64\n",
      " 5   lat_borrow          106202 non-null  float64\n",
      " 6   lon_borrow          106202 non-null  float64\n",
      " 7   end_station_name    106202 non-null  object \n",
      " 8   return_count        106202 non-null  float64\n",
      " 9   lat_return          106202 non-null  float64\n",
      " 10  lon_return          106202 non-null  float64\n",
      " 11  net_activity        106202 non-null  float64\n",
      " 12  lat                 106202 non-null  float64\n",
      " 13  lon                 106202 non-null  float64\n",
      "dtypes: float64(9), int64(1), object(4)\n",
      "memory usage: 11.3+ MB\n"
     ]
    }
   ],
   "source": [
    "daily_activity.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
